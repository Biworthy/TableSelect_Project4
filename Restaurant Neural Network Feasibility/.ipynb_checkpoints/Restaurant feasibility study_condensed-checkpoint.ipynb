{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "301f029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder,MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import h5py\n",
    "import tabpy\n",
    "import tabpy_client\n",
    "from tabpy.tabpy_tools.client import Client\n",
    "client = tabpy_client.Client('http://localhost:9004/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed0f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to install tensorflow for python\n",
    "#import sys\n",
    "\n",
    "#!$sys.executable -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc819cc0",
   "metadata": {},
   "source": [
    "**model evaluation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5e37914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_rest(_arg1):\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    import csv\n",
    "    import os\n",
    "    import re\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import OrdinalEncoder,MinMaxScaler\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from tensorflow.keras.layers import Dense,Dropout\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "    from tensorflow.keras.models import load_model\n",
    "    import h5py\n",
    "    import tabpy\n",
    "    import tabpy_client\n",
    "    from tabpy.tabpy_tools.client import Client\n",
    "    # Read source files\n",
    "    restaurant_bus_df = pd.read_excel('business2_csv.xls')\n",
    "    income_data = pd.read_csv('incomevalues.csv',thousands=',')\n",
    "    restaurant_bus_df.drop(columns=['Unnamed: 0','ID','Latitude','Longitude'],inplace=True)\n",
    "    restaurant_bus_df=restaurant_bus_df.astype(dtype={'Zip-Code':str})\n",
    "    enc = OneHotEncoder()\n",
    "    data=enc.fit_transform(restaurant_bus_df[['Price_Rng']])\n",
    "    restaurant_bus_df['Price_Rng_enc'] = pd.DataFrame(data)\n",
    "    #merging of restaurant and income data\n",
    "    income_data.IncomeperReturn=income_data.IncomeperReturn.apply(lambda x:x.replace('$','').replace(',','.').strip()).astype(float)\n",
    "    income_data.SalaryperReturn=income_data.SalaryperReturn.apply(lambda x:x.replace('$','').replace(',','.').strip()).astype(float)\n",
    "    income_data.TaxPaidperReturn=income_data.TaxPaidperReturn.apply(lambda x:x.replace('$','').replace(',','.').strip()).astype(float)\n",
    "    income_data.drop(columns=['Unnamed: 8','Unnamed: 9','State'],inplace=True)\n",
    "    income_data.City = income_data.City.fillna('Blank')\n",
    "    income_data.drop(index=income_data[income_data.ZipCode=='GEORGIA'].index[0],inplace=True)\n",
    "    #\n",
    "    restaurant_income_data=restaurant_bus_df.merge(right=income_data,how='inner',left_on='Zip-Code',right_on='ZipCode')\n",
    "    zip_codes = restaurant_income_data['Zip-Code'].unique()\n",
    "    cuisines = restaurant_income_data.Cuisine.unique()\n",
    "    unique_cuisines = restaurant_income_data.Cuisine.nunique()\n",
    "\n",
    "    mean_rating=restaurant_income_data.Ratings.unique().mean()\n",
    "    max_rating=restaurant_income_data.Ratings.unique().max()\n",
    "    scores=[int(max(((restaurant_income_data.iloc[i].Ratings-mean_rating)/max_rating)*restaurant_income_data.iloc[i].Reviews,0)) for i in restaurant_income_data.index]\n",
    "\n",
    "    #restaurant_income_data.to_excel('score_data.xlsx', index = False)\n",
    "    restaurant_income_data.drop(columns=['ZipCode','City','Ratings','Reviews','Name','Price_Rng'],inplace=True)\n",
    "\n",
    "    #Prepare the data for training\n",
    "    encoder=OrdinalEncoder()\n",
    "    restaurant_income_data[['Cuisine1','Zip-Code1']]=encoder.fit_transform(restaurant_income_data[['Cuisine','Zip-Code']])\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_df = scaler.fit_transform(restaurant_income_data[['Cuisine1', 'Zip-Code1', 'NumberReturns',\n",
    "       'AdjustedGross Income', 'IncomeperReturn', 'SalaryperReturn',\n",
    "       'TaxPaidperReturn']])\n",
    "    scaled_df2 = pd.DataFrame(scaled_df,columns = ('Cuisine1', 'Zip-Code1', 'NumberReturns','AdjustedGross Income', 'IncomeperReturn', 'SalaryperReturn','TaxPaidperReturn'))\n",
    "    #income_data.to_excel('income_fcst.xlsx', index = False)\n",
    "\n",
    "    #scaled_df2.to_excel('training_model.xlsx', index = False)\n",
    "    #data split between train and test\n",
    "    #scaler_score = MinMaxScaler()\n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_data = np.array(y_scaler.fit_transform(np.expand_dims(scores,axis=-1).astype(int)))\n",
    "    x_data = np.array(scaled_df2)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,train_size=0.8,shuffle=True)\n",
    "    y_train = np.asarray(y_train).astype(int)\n",
    "    y_test = np.asarray(y_test).astype(int)\n",
    "    #deep neural network creation\n",
    "    m = Sequential()\n",
    "    m.add(Dense(100,activation='relu'))\n",
    "    m.add(Dropout(0.2))\n",
    "    m.add(Dense(50,activation='relu'))\n",
    "    m.add(Dropout(0.1))\n",
    "    m.add(Dense(10,activation='relu'))\n",
    "    m.add(Dense(1,activation='relu'))\n",
    "\n",
    "    m.compile(optimizer=Adam(learning_rate=0.0001),loss='mse',metrics=[RootMeanSquaredError()])\n",
    "    #training\n",
    "    chkpt = ModelCheckpoint(filepath='weights.{epoch:02d}-{val_root_mean_squared_error:.4f}.hdf5',monitor='val_root_mean_squared_error',mode='min',save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_root_mean_squared_error',mode='min',patience=3,restore_best_weights=True) \n",
    "    callbacks = [chkpt, early_stopping]\n",
    "    m.fit(x_train,y_train,batch_size=32,epochs=40,validation_data=(x_test,y_test),callbacks=callbacks)\n",
    "    m = load_model('weights.01-0.0010.hdf5')\n",
    "    zipcode = _arg1[0]\n",
    "    #price_range = str(_arg2[0])\n",
    "    top_prediction = ''\n",
    "    print(_arg1)\n",
    "    print(zipcode)\n",
    "    print(type(zip_codes))\n",
    "    if zipcode not in zip_codes:\n",
    "        print('Error!! zip code not in dataset')\n",
    "    else:\n",
    "        Number_of_returns = income_data[income_data.ZipCode==zipcode].NumberReturns.iloc[0]\n",
    "        Gross_income = income_data[income_data.ZipCode==zipcode]['AdjustedGross Income'].iloc[0]\n",
    "        income_per_ret = income_data[income_data.ZipCode==zipcode].IncomeperReturn.iloc[0]\n",
    "        sal_per_ret = income_data[income_data.ZipCode==zipcode].SalaryperReturn.iloc[0]\n",
    "        tax_per_ret = income_data[income_data.ZipCode==zipcode].TaxPaidperReturn.iloc[0]\n",
    "        evaluation_df = pd.DataFrame(data={'Cuisine':cuisines,'Zip-Code':[zipcode]*unique_cuisines,'NumberReturns':[Number_of_returns]*unique_cuisines,'AdjustedGross Income':[Gross_income]*unique_cuisines,'IncomeperReturn':[income_per_ret]*unique_cuisines,'SalaryperReturn':[sal_per_ret]*unique_cuisines,'TaxPaidperReturn':[tax_per_ret]*unique_cuisines})\n",
    "        evaluation_df[['Cuisine','Zip-Code']]=encoder.transform(evaluation_df[['Cuisine','Zip-Code']])\n",
    "        evaluation_df[evaluation_df.columns]=scaler.transform(evaluation_df)\n",
    "        predicted_score = m.predict(evaluation_df)\n",
    "        top_5_pred_idx = np.argpartition(np.squeeze(predicted_score), -1)[-1::]\n",
    "        top_prediction = cuisines[top_5_pred_idx]\n",
    "    return str(top_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e298396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publish the PredictDelay function to TabPy server so it can be used from Tableau\n",
    "\n",
    "client.deploy('pred_rest',\n",
    "                  pred_rest,\n",
    "                  'Returns top restaurant recommendation', override = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c69bc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "11/11 [==============================] - 1s 34ms/step - loss: 0.0032 - root_mean_squared_error: 0.0562 - val_loss: 0.0000e+00 - val_root_mean_squared_error: 0.0000e+00\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0031 - root_mean_squared_error: 0.0558 - val_loss: 0.0000e+00 - val_root_mean_squared_error: 0.0000e+00\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0031 - root_mean_squared_error: 0.0559 - val_loss: 0.0000e+00 - val_root_mean_squared_error: 0.0000e+00\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0031 - root_mean_squared_error: 0.0556 - val_loss: 0.0000e+00 - val_root_mean_squared_error: 0.0000e+00\n",
      "<class 'str'>\n",
      "<class 'numpy.ndarray'>\n",
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"['Specialty Food']\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test in Python\n",
    "pred_rest('30096')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
